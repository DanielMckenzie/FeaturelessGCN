{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_data import load_benchmark\n",
    "from src.normalization import get_adj_feats\n",
    "from src.args import get_args\n",
    "from src.models import get_model\n",
    "from src.utils import accuracy\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "\n",
    "# all tensor, dense\n",
    "dataset_name = 'cora'\n",
    "# dataset_name = input('input dataset name: cora/citeseer/pubmed/...')\n",
    "\n",
    "\n",
    "adj, feats, labels, idx_train, idx_val, idx_test = load_benchmark(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args\n",
    "\n",
    "# model_name = input('choose model: GCN/SGC/GFNN/GFN/AGNN/GIN/...')\n",
    "model_name = 'GCN'\n",
    "args = get_args(model_opt = model_name, dataset = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input for model\n",
    "\n",
    "adj, feats = get_adj_feats(adj = adj, feats = feats, model_opt = model_name, degree = args.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing\n",
    "\n",
    "nb_class = (torch.max(labels) + 1).numpy()\n",
    "Y_onehot =  torch.zeros(labels.shape[0], nb_class).scatter_(1, labels.unsqueeze(-1), 1)\n",
    "\n",
    "nb_each_class_train = torch.sum(Y_onehot[idx_train], dim = 0)\n",
    "nb_each_class_inv_train = torch.tensor(np.power(nb_each_class_train.numpy(), -1).flatten())\n",
    "nb_each_class_inv_mat_train = torch.diag(nb_each_class_inv_train)\n",
    "\n",
    "nb_each_class_val = torch.sum(Y_onehot[idx_val], dim = 0)\n",
    "nb_each_class_inv_val = torch.tensor(np.power(nb_each_class_val.numpy(), -1).flatten())\n",
    "nb_each_class_inv_mat_val = torch.diag(nb_each_class_inv_val)\n",
    "\n",
    "nb_each_class_test = torch.sum(Y_onehot[idx_test], dim = 0)\n",
    "nb_each_class_inv_test = torch.tensor(np.power(nb_each_class_test.numpy(), -1).flatten())\n",
    "nb_each_class_inv_mat_test = torch.diag(nb_each_class_inv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model = get_model(model_opt = model_name, nfeat = feats.size(1), \\\n",
    "                  nclass = labels.max().item()+1, nhid = args.hidden, \\\n",
    "                  dropout = args.dropout, cuda = args.cuda, \\\n",
    "                  dataset = dataset_name, degree = args.degree)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "# if args.cuda:\n",
    "#     if model_name!='AGNN' and model_name!='GIN':\n",
    "#         model.cuda()\n",
    "#         feats = feats.cuda()\n",
    "#         adj = adj.cuda()\n",
    "#         labels = labels.cuda()\n",
    "#         idx_train = idx_train.cuda()\n",
    "#         idx_val = idx_val.cuda()\n",
    "#         idx_test = idx_test.cuda()\n",
    "    \n",
    "    \n",
    "# Print model's state_dict    \n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor,\"\\t\",model.state_dict()[param_tensor].size()) \n",
    "print(\"optimizer's state_dict:\")\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name,\"\\t\",optimizer.state_dict()[var_name])\n",
    "    \n",
    "# Print parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delt = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output, fp1, fp2 = model(feats, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output, fp1, fp2 = model(feats, adj)\n",
    "    \n",
    "    CE_loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    loss_val = CE_loss_val\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    \n",
    "    CE_loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    loss_test = CE_loss_test\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    \n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'loss_test: {:.4f}'.format(loss_test.item()),\n",
    "          'acc_test: {:.4f}'.format(acc_test.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "    return epoch+1, loss_train.item(), acc_train.item(), loss_val.item(), \\\n",
    "            acc_val.item(), loss_test.item(), acc_test.item(), time.time() - t, \\\n",
    "            output, fp1, fp2\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_log = []\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "temp_val_loss = 999999\n",
    "temp_val_acc = 0\n",
    "temp_test_loss = 0\n",
    "temp_test_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "\n",
    "    epo, trainloss, trainacc, valloss, valacc, testloss, testacc, epotime, output, fp1, fp2 = train(epoch)\n",
    "    training_log.append([epo, trainloss, trainacc, valloss, valacc, testloss, testacc, epotime])\n",
    "\n",
    "    if valacc >= temp_val_acc:\n",
    "        temp_val_loss = valloss\n",
    "        temp_val_acc = valacc\n",
    "        temp_test_loss = testloss\n",
    "        temp_test_acc = testacc\n",
    "        propagation_feats = fp1\n",
    "        before_softmax = fp2\n",
    "        after_softmax = output\n",
    "        \n",
    "        if model_name == 'AFGNN':\n",
    "            temp_weight = torch.softmax(model.state_dict()['gc1.linear_weight'].data,dim=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result\n",
    "\n",
    "\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print(\"Best result:\",\n",
    "          \"val_loss=\",temp_val_loss,\n",
    "            \"test_loss=\",temp_test_loss,\n",
    "             \"test_acc=\",temp_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
